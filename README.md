[**中文**](./README(0).md) | [**English**](./README(1).md)

<p align="center" width="100%">
<a href="https://github.com/NEU-DataMining/Emo-LLM" target="_blank"><img src="logo.png" alt="EMO_LLM" style="width: 35%; min-width: 300px; display: block; margin: auto;"></a>
</p>

# PICA: A comprehensive language model with satisfying empathetical ability


本项目收集了文本情感分析、对话情感分析、个性对话生成、共情对话、情感原因对提取五个领域三十多个数据集，经过对比和筛选，保留了其中23个数据集，同时对满足条件的数据集进行多任务改造，最终得到35个不同版本的数据集，分别用于五类不同的任务训练：文本情感分类、对话情感分类、情感原因对提取、对话生成、对话情景推理。然后以。。。模型为基座，利用进行。。。的训练。训练任务包括在共情任务上，。。。。。在其他方面的任务上，。。。。。

我们以拉丁文中喜鹊的表达PICA作为模型的名称，希望模型通过语言共情，能够让人们如同看到喜鹊一般，把心中的阴霾一扫而空，这正是我们工作的动力所在。

### 更新 

&#x1F5D3; **2023.7.11** 公布了由少量自建共情数据集（中文）精调得到的模型的数据

&#x1F43E; **2023.6.29** 实现了多任务数据集共同精调得到的模型，内测模型效果

### 使用指南

模型的环境是
安装的依赖包有
下载。。到。。。。。
运行以下命令行，把路径改为。。。所在路径

```
bash emo-llm
ssh victory/of/NEU-Data_Mining
```

### 案例分析

1️⃣ 对抽象问题咨询的测试

###### 用户：
> 我总是对自己的能力感到怀疑，做什么事情都会犹豫，然后失去最好的去做的机会，之后又非常懊悔，你说该怎么办？
###### PICA:
> 感到犹豫和拖延是很正常的事，特别是在面对重要决策时。首先，你可以尝试分解任务，将它们分解成为更小的步骤，这样可以帮助你更容易地完成任务。
###### 用户：
> 哦，我明白了，通过分解成更小的步骤，然后再努力去做，不要拖延，是吗？可是有时候，我会觉得就算做了也没有用，对自己未来不抱希望了，没有做事的动力，该怎么办呢？
###### PICA:
>有时候，我们可能会对自己没有动力而感到沮丧，但是请相信，你所做的每一个步骤都会为未来做好准备。同时，你可以寻找支持和鼓励的人，这样可以让你更有动力去完成任务。
###### 用户：
>谢谢你的帮助。当看到身边的人很优秀而自己比较落后，该怎么才能继续坚持努力，不要打乱自己的节奏呢？
###### PICA:
>每个人的人生轨迹不同，没有必要与人比较。重要的是，你能够实现自己的目标，而不是只是与他人的差距。记住，每个人都有自己的节奏和目标，你的努力也会得到回报

模型对情感能够准确识别，并给出积极的引导

2️⃣ 对具体问题咨询的测试

###### 用户：
>我现在处于高二的暑假，需要补课。我的妈妈要我同时参加家教和集体补课，我的爸爸说这样就没有整理复习的时间了，家教针对性强些，只参加家教课，老师说集体补课学习氛围更好，只需要集体补课就够了。我自己一点注意也没有，你说该怎么办？
###### PICA:
>我明白你的困惑和纠结。 在这种情况下，你可以考虑与你的妈妈和爸爸进行沟通，告诉他们你的困惑和需要调整的学习计划。你可以提出你希望专注于学习的内容，并提供一些具体的建议。同时，你也可以寻求其他学生或老师的帮助，获取更多的学习资源和支持。
###### 用户：
>其实我是很想两个都参加的，可是怕自己给家庭造成经济负担，然后还是没学好让父母失望。
###### PICA:
>这是一个很好的问题！你可以尝试与你的妈妈和爸爸讨论一下，看看他们是否能够理解你的困境，并提供一些解决方案。同时，你也可以考虑与同学或老师建立良好的合作关系，互相帮助和支持。这样，你可以更好地平衡学习和家庭的责任。
###### 用户：
>你能给我些鼓励，让我坚持自己的想法，并且为即将到来的高考好好拼搏一番吗？
###### PICA:
>当然可以！你已经迈出了第一步，相信自己能够实现目标。记住，成功需要坚持和努力。相信自己的能力，相信你所做出的决定，继续朝着自己的目标努力前进。相信自己，你一定能够取得好成绩！

模型对事件的理解不够，还停留在单词级的理解上（例如机械捕捉经济负担这个词，然后用“责任”方面的表述回复），有一定的违和感，但是能够突出解决问题和共情方面的特点。

### 效果展示

下面的视频展示了我们的emo-llm的实际使用效果

### 数据集

使用的数据集包括情感分析领域的各方向的公共数据集，经过筛选、任务改造、格式整合得到最终数据集

#### 任务改造

如何把分类任务与生成任务互相转化
如何添加进指令

#### 格式整合

所有数据集整合到以下格式
* 'task_type'：所属于的训练任务类型
* 'dataset'：所用数据集名称
* 'instruction': 指令
* 'instances'：训练样本 
* 'is_classification'：区分生成任务和分类任务
*  'name'： 具体数据集做的任务名称

### 任务描述

Emo-LLM模型主要在以下五类任务中训练，激发大语言模型的语言知识和共情能力：

#### 文本情感分类

该任务给定一段文本及候选情感标签，让模型选择适当的情感标签

#### 对话情感分类

该任务给定历史对话、当前对话、候选情感标签，让模型选择恰当的情感标签，让模型能够理解和识别对话中的情感

#### 情感原因抽取

该任务给定一段文本或对话，找到其中的情绪语情绪的原因，帮助模型深入理解句子中的情感及其原因，进一步提高模型的情感分析能力

#### 可控对话生成

该任务给定一段对话历史，给定控制信息，生成回复，让模型能够根据控制信息生成符合要求的对话

#### 对话背景推理

该任务给定一段对话，推理对话背景，让模型能够基于对话内容和上下文推理对话的情景等信息，提高对话系统的智能交互效果

### 模型训练与基线模型

#### 训练架构与方式

#### 模型特色

* **输出模块设计**：
* **迭代式情感与个性适应**：

### 模型评估

#### 基线模型介绍

#### 训练结果与分析

### 项目参与人员

### 致谢

### 引用

```
@misc{    ,
      title={   },
      author={   },
      year={2023},
      eprint={   },
      archivePrefix={arXiv},
      primaryClass={    }
}
```
